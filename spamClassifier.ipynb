{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a811ec8-1917-4eb5-91c4-979ab9e1ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the Dataset\n",
    "\n",
    "import pandas as pd\n",
    "messages = pd.read_csv('smsspamcollection/SMSSpamCollection', sep='\\t',\n",
    "                           names=[\"label\", \"message\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5288df1d-3f35-479f-9837-06a0bec769fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79a1052d-a67e-4954-b09a-79678e95e51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\sai\n",
      "[nltk_data]     sushanth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data cleaning and preprocessing\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcac1b02-39bb-4973-a82e-a8b93f22ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3d7c17-d831-4db1-afc3-c6155580a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(0, len(messages)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['message'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f6559f2-e05b-4c75-807a-e6c72018beb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go jurong point crazi avail bugi n great world la e buffet cine got amor wat',\n",
       " 'ok lar joke wif u oni',\n",
       " 'free entri wkli comp win fa cup final tkt st may text fa receiv entri question std txt rate c appli',\n",
       " 'u dun say earli hor u c alreadi say']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "981942c1-4b07-479b-9666-e0e7c4cf3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=4500)\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ebf2b99-8a6a-4ee1-aa61-c0a1e094959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.get_dummies(messages['label'])\n",
    "y=y.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1917c72-19a6-49ab-bd17-fc325372c0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "681d9098-c685-4c32-b5df-ca1aa29512c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1d1b480-df8f-4874-9d48-627a9b81023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model using Naive bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f9505c2-a727-4038-9ead-84fabfa1f84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, ..., False,  True, False])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=spam_detect_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca1f9870-0836-4c7b-a16a-1e6fdb26d94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[946   9]\n",
      " [  7 153]] 0.9856502242152466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "confusion_m=confusion_matrix(y_test,y_pred)\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "print(confusion_m,accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f315f1c4-7ea3-4519-b3e5-ad67eb4c9974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confusion matrix</th>\n",
       "      <th>accuracy score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[946, 9], [7, 153]]</td>\n",
       "      <td>0.98565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       confusion matrix  accuracy score\n",
       "0  [[946, 9], [7, 153]]         0.98565"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics=pd.DataFrame({'confusion matrix':[confusion_m],'accuracy score':[accuracy]})\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5818ea0-63c1-48f6-9699-be8bc4f7b0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: SPAM\n"
     ]
    }
   ],
   "source": [
    "def predict_spam_or_ham(input_text):\n",
    "    # Preprocess the input\n",
    "    ps = PorterStemmer()\n",
    "    review = re.sub('[^a-zA-Z]', ' ', input_text)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "\n",
    "    # Vectorize the input\n",
    "    input_vector = cv.transform([review]).toarray()\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = spam_detect_model.predict(input_vector)\n",
    "\n",
    "    # Output the prediction\n",
    "    if prediction == 1:\n",
    "        return \"SPAM\"\n",
    "    else:\n",
    "        return \"HAM\"\n",
    "\n",
    "# Test the function\n",
    "unknown_input = \"Congratulations! You've won a free cruise. Reply 'YES' to claim your prize.\"\n",
    "prediction = predict_spam_or_ham(unknown_input)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a7d6956-757c-4637-a6b4-f39daabb65d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: HAM\n"
     ]
    }
   ],
   "source": [
    "# Test with a non-spam input\n",
    "non_spam_input = \"Hey, how are you doing? Are you free for lunch tomorrow?\"\n",
    "prediction = predict_spam_or_ham(non_spam_input)\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20201ed2-941b-43ad-aa38-95a21fb50a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Train your model\n",
    "spam_detect_model = MultinomialNB().fit(X_train, y_train)\n",
    "# Train the CountVectorizer with the training data\n",
    "cv.fit(corpus)\n",
    "with open('cv.pkl', 'wb') as file:\n",
    "    pickle.dump(cv, file)\n",
    "# Save the model to a file\n",
    "with open('spam_model.pkl', 'wb') as file:\n",
    "    pickle.dump(spam_detect_model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5de3e4d9-c251-47fe-ade7-e78fee3e642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from file\n",
    "with open('spam_model.pkl', 'rb') as file:\n",
    "    spam_detect_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf41bb37-fbcd-4591-bf21-8569a7cd630a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: SPAM\n"
     ]
    }
   ],
   "source": [
    "# Example text for prediction\n",
    "input_text = \"Congratulations! You've won a free cruise. Reply 'YES' to claim your prize.\"\n",
    "\n",
    "# Preprocess the input text\n",
    "ps = PorterStemmer()\n",
    "review = re.sub('[^a-zA-Z]', ' ', input_text)\n",
    "review = review.lower()\n",
    "review = review.split()\n",
    "review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "review = ' '.join(review)\n",
    "\n",
    "# Vectorize the input\n",
    "input_vector = cv.transform([review]).toarray()\n",
    "\n",
    "# Make prediction using the loaded model\n",
    "prediction = spam_detect_model.predict(input_vector)\n",
    "\n",
    "# Output the prediction\n",
    "if prediction == 1:\n",
    "    print(\"Prediction: SPAM\")\n",
    "else:\n",
    "    print(\"Prediction: HAM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e81598-c91f-44d4-8327-8ae4f30aa70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dce860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
